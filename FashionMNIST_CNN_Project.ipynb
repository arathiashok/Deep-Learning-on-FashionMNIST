{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cce4f9d3",
      "metadata": {
        "id": "cce4f9d3"
      },
      "source": [
        "# CS:4420 Spring 2025 Project — FashionMNIST CNN\n",
        "\n",
        "This notebook implements the solution for all 5 tasks as outlined in the project description."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c23aa2",
      "metadata": {
        "id": "29c23aa2"
      },
      "source": [
        "## Task 1: Implementing CNN from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cf0adb48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf0adb48",
        "outputId": "20c0ec76-b757-4d39-8cdd-4100c6a1390b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FashionCNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FashionCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = self.pool3(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "model = FashionCNN()\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13378877",
      "metadata": {
        "id": "13378877"
      },
      "source": [
        "## Task 2: Training and Testing CNN (Train/Val/Test Split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b536436d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b536436d",
        "outputId": "c1492b2b-01a8-42b2-fcb1-4035703d9a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.5MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 197kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.69MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Ratio vs Accuracy:\n",
            "0% Val: 90.51%\n",
            "10% Val: 91.09%\n",
            "20% Val: 90.43%\n",
            "30% Val: 89.78%\n",
            "40% Val: 89.02%\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "def train_val_test(val_split_ratio):\n",
        "    total_train = len(train_data)\n",
        "    val_size = int(val_split_ratio * total_train)\n",
        "    train_size = total_train - val_size\n",
        "    train_set, val_set = random_split(train_data, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=64, shuffle=False)\n",
        "    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "    model = FashionCNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "results = {}\n",
        "for ratio in [0.0, 0.1, 0.2, 0.3, 0.4]:\n",
        "    acc = train_val_test(ratio)\n",
        "    results[ratio] = acc\n",
        "\n",
        "print(\"Validation Ratio vs Accuracy:\")\n",
        "for k, v in results.items():\n",
        "    print(f\"{int(k*100)}% Val: {v:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above evaluation on the model's performance on the test set while varying the validation set size (0%, 10%, 20%, 30%, 40%) during training, the model achieved the highest accuracy with a **10% validation split** and With no validation split and the model performed reasonably well, but slightly worse than the 10% split.\n",
        "\n",
        "Takeaway:\n",
        "\n",
        "*   A small validation set (e.g., 10%) helps improve generalization without taking away too much training data.\n",
        "*   Larger validation sets reduce training size, which may lead to underfitting and lower test performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "7QtWocQZo_9x"
      },
      "id": "7QtWocQZo_9x"
    },
    {
      "cell_type": "markdown",
      "id": "ba96ba1b",
      "metadata": {
        "id": "ba96ba1b"
      },
      "source": [
        "## Task 3: Learning Rate Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bd68318c",
      "metadata": {
        "id": "bd68318c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5e0d5a-938a-4204-9812-94ef5b9129dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing LR: 0.001\n",
            "Testing LR: 0.01\n",
            "Testing LR: 0.1\n",
            "Testing LR: 1\n",
            "Testing LR: 10\n",
            "Learning Rate vs Accuracy:\n",
            "LR 0.001: 41.21%\n",
            "LR 0.01: 82.49%\n",
            "LR 0.1: 89.37%\n",
            "LR 1: 10.00%\n",
            "LR 10: 10.00%\n"
          ]
        }
      ],
      "source": [
        "def test_learning_rates(rates, best_val_split):\n",
        "    acc_results = {}\n",
        "    for lr in rates:\n",
        "        print(f\"Testing LR: {lr}\")\n",
        "        total_train = len(train_data)\n",
        "        val_size = int(best_val_split * total_train)\n",
        "        train_size = total_train - val_size\n",
        "        train_set, val_set = random_split(train_data, [train_size, val_size])\n",
        "        train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "        test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "        model = FashionCNN().to(device)\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(10):\n",
        "            model.train()\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)#passing images to model to get output\n",
        "                loss = criterion(outputs, labels)#loss value based on prediction and ground truth\n",
        "                loss.backward()\n",
        "                optimizer.step()#update models weight\n",
        "\n",
        "        model.eval()\n",
        "        correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        acc_results[lr] = 100 * correct / total\n",
        "    return acc_results\n",
        "\n",
        "learning_rates = [0.001, 0.01, 0.1, 1, 10]\n",
        "lr_results = test_learning_rates(learning_rates, best_val_split=0.1)\n",
        "\n",
        "print(\"Learning Rate vs Accuracy:\")\n",
        "for k, v in lr_results.items():\n",
        "    print(f\"LR {k}: {v:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Findings:\n",
        "*  0.001 was too small — training was very slow and underfitting occurred.\n",
        "\n",
        "*  0.01 provided decent learning but didn’t fully optimize performance.\n",
        "\n",
        "*  0.1 was optimal — model trained efficiently and achieved the highest accuracy.\n",
        "\n",
        "*  1 and 10 led to immediate performance breakdown — likely due to unstable gradients or exploding loss values, preventing the model from learning."
      ],
      "metadata": {
        "id": "8_5GBOytIPdC"
      },
      "id": "8_5GBOytIPdC"
    },
    {
      "cell_type": "markdown",
      "id": "0bdb7ea4",
      "metadata": {
        "id": "0bdb7ea4"
      },
      "source": [
        "## Task 4: Training Algorithm Comparison (SGD vs Adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aefae474",
      "metadata": {
        "id": "aefae474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8dd5d59-78d2-40ba-ab9a-1019f76113cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD Accuracy: 90.48%, Adam Accuracy: 10.00%\n"
          ]
        }
      ],
      "source": [
        "def compare_optimizers(lr, val_split=0.1):\n",
        "    total_train = len(train_data)\n",
        "    val_size = int(val_split * total_train)\n",
        "    train_size = total_train - val_size\n",
        "    train_set, val_set = random_split(train_data, [train_size, val_size])\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "    def train_with_optimizer(optimizer_fn):\n",
        "        model = FashionCNN().to(device)\n",
        "        optimizer = optimizer_fn(model.parameters(), lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        for epoch in range(10):\n",
        "            model.train()\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return model\n",
        "\n",
        "    sgd_model = train_with_optimizer(optim.SGD)\n",
        "    adam_model = train_with_optimizer(optim.Adam)\n",
        "\n",
        "    def test_model(model):\n",
        "        model.eval()\n",
        "        correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        return 100 * correct / total\n",
        "\n",
        "    return test_model(sgd_model), test_model(adam_model)\n",
        "\n",
        "sgd_acc, adam_acc = compare_optimizers(lr=0.1)\n",
        "print(f\"SGD Accuracy: {sgd_acc:.2f}%, Adam Accuracy: {adam_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Findings:\n",
        "*  SGD significantly outperformed Adam in this experiment, achieving 90.48% test accuracy.\n",
        "\n",
        "*  The Adam optimizer, despite being adaptive and typically more efficient, resulted in only 10% accuracy, indicating it failed to learn effectively under the same learning rate.\n",
        "\n",
        "*  This performance gap suggests that Adam is more sensitive to learning rate tuning — the value of 0.1, which worked well for SGD, is likely too high for Adam, causing divergence or ineffective weight updates."
      ],
      "metadata": {
        "id": "U5BXIQs0I4sH"
      },
      "id": "U5BXIQs0I4sH"
    },
    {
      "cell_type": "markdown",
      "id": "b36cf92d",
      "metadata": {
        "id": "b36cf92d"
      },
      "source": [
        "## Task 5: AUC for One-Class Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7j23QLxNqKEd",
      "metadata": {
        "id": "7j23QLxNqKEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0696e2a3-a371-4f2f-d54f-8bb563ff28f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score for class '2' (positive vs rest): 0.9900\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "total_train = len(train_data)\n",
        "val_size = int(0.1 * total_train)\n",
        "train_size = total_train - val_size\n",
        "train_set, val_set = random_split(train_data, [train_size, val_size])\n",
        "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "def train_with_optimizer(optimizer_fn):\n",
        "        model = FashionCNN().to(device)\n",
        "        optimizer = optimizer_fn(model.parameters(), lr=0.1)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        for epoch in range(10):\n",
        "            model.train()\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return model\n",
        "\n",
        "sgd_model = train_with_optimizer(optim.SGD)\n",
        "\n",
        "model = sgd_model\n",
        "model.eval()\n",
        "\n",
        "y_true = []\n",
        "y_scores = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "        class2_probs = probs[:, 2].cpu().numpy()\n",
        "        y_scores.extend(class2_probs)\n",
        "\n",
        "        binary_labels = (labels == 2).int().numpy()\n",
        "        y_true.extend(binary_labels)\n",
        "\n",
        "auc_score = roc_auc_score(y_true, y_scores)\n",
        "print(f\"AUC Score for class '2' (positive vs rest): {auc_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Findings:\n",
        "*  An AUC score of 0.9900 indicates excellent discriminative ability — the model is highly effective at ranking true class-2 images above non-class-2 images.\n",
        "\n",
        "*  This result suggests the model learned distinctive features for class \"2\", even though it was trained in a multi-class setting."
      ],
      "metadata": {
        "id": "DC9y533bJfXZ"
      },
      "id": "DC9y533bJfXZ"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}